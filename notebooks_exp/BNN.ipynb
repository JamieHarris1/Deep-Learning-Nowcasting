{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6eab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import os\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "from patsy import dmatrix\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from data_tools.data_utils import ReportingDataset, create_data_split\n",
    "project_dir = project_dir = Path.cwd().parent\n",
    "trunc_D = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,45,46,54,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,45,46,54,56,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,45,46,54,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,45,46,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,45,46,54,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,50,52,54,56,62,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,50,52,54,56,62,74,85,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (22,44,45,46,50,52,54,56,62,74,85,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (6,10,18,21,22,44,45,46,50,52,54,56,62,64,68,74,85,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n",
      "/Users/jamieharris/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/src/data_tools/data_utils.py:21: DtypeWarning: Columns (25,27,29,31,33,46,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(os.path.join(base_folder_path, file)) for file in files]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "create_data_split(\n",
    "    start_year=2013,\n",
    "    end_year=2020,\n",
    "    D=trunc_D,\n",
    "    data_folder_path = project_dir / \"data\",\n",
    "    input_filename=\"DENGSP.csv\",\n",
    "    train_prop=0.7,\n",
    "    val_prop=0.2,\n",
    "    test_prop=0.1\n",
    ")\n",
    "complete_df = pd.read_csv(project_dir / \"data\" / \"model\" / \"complete_data.csv\",\n",
    "    parse_dates=True,\n",
    "    date_format=\"%Y %b\",\n",
    "    index_col=0,\n",
    "    dtype={\"value\": float},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7910843b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'complete_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_true = \u001b[43mcomplete_df\u001b[49m.sum(axis=\u001b[32m1\u001b[39m)\n\u001b[32m      2\u001b[39m y_true.index = pd.to_datetime(y_true.index)\n\u001b[32m      3\u001b[39m y_true\n",
      "\u001b[31mNameError\u001b[39m: name 'complete_df' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = complete_df.sum(axis=1)\n",
    "y_true.index = pd.to_datetime(y_true.index)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0be3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(project_dir / \"data\" / \"model\" / \"training_data.csv\",\n",
    "    parse_dates=True,\n",
    "    date_format=\"%Y %b\",\n",
    "    index_col=0,\n",
    "    dtype={\"value\": float},\n",
    ")\n",
    "val_df = pd.read_csv(project_dir / \"data\" / \"model\" / \"validation_data.csv\",\n",
    "    parse_dates=True,\n",
    "    date_format=\"%Y %b\",\n",
    "    index_col=0,\n",
    "    dtype={\"value\": float},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a097f7a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m reporting_triangle = np.zeros(shape=(\u001b[38;5;28mlen\u001b[39m(train_df)-model_D, model_D, model_D))\n\u001b[32m     19\u001b[39m k = \u001b[32m15\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m train_max_val = \u001b[43mtrain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m train_max_val\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model_D, \u001b[38;5;28mlen\u001b[39m(train_df)):\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# get reporting triangles for each time points\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Imperial/Dengue-Nowcasting-Thesis/NowcastingVenv/lib/python3.12/site-packages/numpy/core/_methods.py:41\u001b[39m, in \u001b[36m_amax\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amax\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     40\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "def mask_matrix(matrix, D):\n",
    "        masked_matrix = matrix.copy()\n",
    "        nrow, ncol = masked_matrix.shape\n",
    "\n",
    "        for i in range(nrow):\n",
    "            for j in range(ncol):\n",
    "                if i + j > D - 1:\n",
    "                     masked_matrix[i, j] = False\n",
    "        return  masked_matrix\n",
    "\n",
    "model_D = 40\n",
    "M = 0\n",
    "mask = np.ones(shape=(model_D, model_D), dtype=bool)\n",
    "mask = mask_matrix(mask, model_D)\n",
    "\n",
    "reporting_triangle = np.zeros(shape=(len(train_df)-model_D, model_D, model_D))\n",
    "\n",
    "\n",
    "k = 15\n",
    "train_max_val = train_df.values.max()\n",
    "train_max_val\n",
    "for t in range(model_D, len(train_df)):\n",
    "    \n",
    "    # get reporting triangles for each time points\n",
    "    matrix = train_df.copy().iloc[t-model_D:t, :model_D]\n",
    "    matrix_bool = np.ones_like(matrix, dtype=bool)\n",
    "    matrix[~mask] = 0\n",
    "    reporting_triangle[t-model_D, :, :] = matrix\n",
    "    reporting_triangle[t-model_D, :, :] = reporting_triangle[t-model_D, :, :] / train_max_val\n",
    "\n",
    "print(reporting_triangle.shape)\n",
    "print(reporting_triangle[-1, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f203de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def silu(x):\n",
    "    return x * pm.math.sigmoid(x)\n",
    "\n",
    "def sampler_kwargs():\n",
    "    return dict(\n",
    "        nuts_sampler=\"nutpie\",\n",
    "        chains=2,\n",
    "        draws=300,\n",
    "        tune=1000,\n",
    "        target_accept=0.95,\n",
    "        max_treedepth=15,\n",
    "        nuts_sampler_kwargs={\"backend\": \"jax\", \"gradient_backend\": \"jax\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len_train = 200\n",
    "train_obs = np.array(train_df.copy().iloc[model_D: model_D + len_train])\n",
    "train_triangle = reporting_triangle[:len_train, :, :]\n",
    "t = np.arange(0, len(train_triangle))\n",
    "t = np.arange(len(train_triangle))  # full time index\n",
    "t_week = t % 7                      # day of the week number\n",
    "\n",
    "\n",
    "\n",
    "# Global trend spline with 6 basis funcs and 3 degree polynomial\n",
    "spline_trend = dmatrix(\n",
    "    \"bs(t, df=10, degree=3, include_intercept=False)\", {\"t\": t}, return_type='dataframe'\n",
    ")\n",
    "X_trend = np.asarray(spline_trend)\n",
    "\n",
    "# cc is syclic cubic spline\n",
    "spline_week = dmatrix(\n",
    "    \"cc(t_week, df=6)\", {\"t_week\": t_week}, return_type='dataframe'\n",
    ")\n",
    "X_week = np.asarray(spline_week)\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    # Trend spline coefficients\n",
    "    sigma_trend = pm.HalfNormal(\"sigma_trend\", 3)\n",
    "    beta_trend = pm.Normal(\"beta_trend\", mu=0, sigma=sigma_trend, shape=X_trend.shape[1])\n",
    "    \n",
    "    # Cyclic spline coefficients (seasonality)\n",
    "    sigma_week = pm.HalfNormal(\"sigma_week\", 3)\n",
    "    beta_week = pm.Normal(\"beta_week\", mu=0, sigma=sigma_week, shape=X_week.shape[1])\n",
    "    \n",
    "    log_lam = pm.Deterministic(\n",
    "        \"log_lam\", pm.math.dot(X_trend, beta_trend) + pm.math.dot(X_week, beta_week)\n",
    "    )\n",
    "    lam = pm.Deterministic(\"lam\", pm.math.exp(pm.math.clip(log_lam, -5, 10)))\n",
    "\n",
    "\n",
    "    # Neural net proportions\n",
    "    T, D, F = train_triangle.shape\n",
    "    n_hidden = 8\n",
    "\n",
    "    h0 = pm.math.flatten(train_triangle, ndim=2)  # (T, D*F)\n",
    "    \n",
    "    W1 = pm.Normal(\"W1\", 0, 0.3, shape=(D*F, n_hidden))\n",
    "    b1_net = pm.Normal(\"b1_net\", 0, 0.3, shape=(n_hidden,))\n",
    "    h1 = silu(pm.math.dot(h0, W1) + b1_net)\n",
    "\n",
    "    W2 = pm.Normal(\"W2\", 0, 0.3, shape=(n_hidden, D))\n",
    "    b2_net = pm.Normal(\"b2_net\", 0, 0.3, shape=(D,))\n",
    "    p_raw = pm.math.dot(h1, W2) + b2_net\n",
    "\n",
    "\n",
    "    p_raw = pm.math.clip(p_raw, -10, 10)\n",
    "    p = pm.Deterministic(\"p\", pm.math.softmax(p_raw, axis=1))\n",
    "\n",
    "    mu = pm.Deterministic(\"mu\", lam[:, None] * p)\n",
    "    mu_clipped = pm.math.clip(mu, 1e-3, 1e4)\n",
    "\n",
    "    alpha = pm.Exponential(\"alpha\", 5)\n",
    "    z = pm.NegativeBinomial(\"z\", mu_clipped, alpha, observed=train_obs)\n",
    "\n",
    "    idata = pm.sample(**sampler_kwargs())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0846b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triangle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PNN.NowcastPNN import NowcastPNN\n",
    "import torch\n",
    "\n",
    "M = 0\n",
    "PNN_train_triangle = reporting_triangle[:len_train, :, :]\n",
    "nowcast_pnn = NowcastPNN(past_units=M+model_D, max_delay=model_D, conv_channels=[16, 1], hidden_units=[16, 8], dropout_probs=[0.3, 0.1])\n",
    "nowcast_pnn.load_state_dict(torch.load(f\"../src/outputs/weights/weights-{M+model_D}-{model_D}\"))\n",
    "\n",
    "# Put model in eval mode with dropout active\n",
    "nowcast_pnn.eval()\n",
    "nowcast_pnn.drop1.train()\n",
    "nowcast_pnn.drop2.train()\n",
    "\n",
    "n_samples = 1000\n",
    "preds = np.zeros(shape=(len(train_triangle), n_samples))\n",
    "for i in range(n_samples):\n",
    "    matrix = torch.tensor(PNN_train_triangle)\n",
    "    preds[:, i] = nowcast_pnn(matrix).sample().numpy()\n",
    "    \n",
    "\n",
    "PNN_preds = np.quantile(preds, 0.5, axis=1)\n",
    "PNN_lower = np.percentile(preds, 2.5, axis=1)\n",
    "PNN_upper = np.percentile(preds, 97.5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_post_samples = az.extract(idata, group='posterior', num_samples=1000)['lam']\n",
    "lam_med = np.percentile(lam_post_samples, 50, axis=1)\n",
    "lam_lower = np.percentile(lam_post_samples, 2.5, axis=1)\n",
    "lam_upper = np.percentile(lam_post_samples, 97.5, axis=1)\n",
    "\n",
    "\n",
    "y_plot = y_true[model_D:model_D + len_train]\n",
    "y_plot.index = pd.to_datetime(y_plot.index)\n",
    "\n",
    "\n",
    "plt.plot(y_plot.index, y_plot, label='y')\n",
    "\n",
    "plt.plot(y_plot.index, lam_med, label='BNN', color='green')\n",
    "# plt.fill_between(y_plot.index, lam_lower, lam_upper, color='green', alpha=0.2, label='BNN 95% CI')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(y_plot.index, PNN_preds, label='PNN', color='orange')\n",
    "# plt.fill_between(y_plot.index, PNN_lower, PNN_upper, color='orange', alpha=0.2, label='PNN 95% CI')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(\"Number of Dengue Fever Cases in Sao Paulo, Brazil\")\n",
    "plt.xlabel(\"Date of First Symptom\")\n",
    "plt.ylabel(\"Case Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635171e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_posterior = az.extract(idata, group='posterior', num_samples=1000)\n",
    "\n",
    "def get_train_post(var):\n",
    "    return np.percentile(train_posterior[var], 50, axis=-1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17448974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BNN_nowcast(t, len_eval, progressbar):\n",
    "    eval_triangle = reporting_triangle[t - len_eval: t, :, :]\n",
    "    eval_obs = eval_triangle[-1, :, :] * train_max_val\n",
    "\n",
    "\n",
    "    t = np.arange(0, len(eval_triangle))\n",
    "    t = np.arange(len(eval_triangle))  # full time index\n",
    "    t_week = t % 7                      # day of the week number\n",
    "\n",
    "    mask = np.ones_like(eval_obs, dtype=bool)\n",
    "    mask[-model_D:] = mask_matrix(mask[-model_D:], model_D)\n",
    "\n",
    "\n",
    "\n",
    "    # Global trend spline with 6 basis funcs and 3 degree polynomial\n",
    "    spline_trend = dmatrix(\n",
    "        \"bs(t, df=10, degree=3, include_intercept=False)\", {\"t\": t}, return_type='dataframe'\n",
    "    )\n",
    "    X_trend = np.asarray(spline_trend)\n",
    "\n",
    "    # cc is syclic cubic spline\n",
    "    spline_week = dmatrix(\n",
    "        \"cc(t_week, df=6)\", {\"t_week\": t_week}, return_type='dataframe'\n",
    "    )\n",
    "    X_week = np.asarray(spline_week)\n",
    "\n",
    "\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # Trend spline coefficients\n",
    "        sigma_trend = pm.HalfNormal(\"sigma_trend\", 3)\n",
    "        beta_trend = pm.Normal(\"beta_trend\", mu=0, sigma=sigma_trend, shape=X_trend.shape[1])\n",
    "        \n",
    "        # Cyclic spline coefficients (seasonality)\n",
    "        sigma_week = pm.HalfNormal(\"sigma_week\", 3)\n",
    "        beta_week = pm.Normal(\"beta_week\", mu=0, sigma=sigma_week, shape=X_week.shape[1])\n",
    "        \n",
    "        log_lam = pm.Deterministic(\n",
    "            \"log_lam\", pm.math.dot(X_trend, beta_trend) + pm.math.dot(X_week, beta_week)\n",
    "        )\n",
    "        lam = pm.Deterministic(\"lam\", pm.math.exp(pm.math.clip(log_lam, -5, 10)))\n",
    "\n",
    "\n",
    "        # Neural net proportions\n",
    "        T, D, F = eval_triangle.shape\n",
    "        n_hidden = 8\n",
    "        net_sd = 0.1\n",
    "\n",
    "        h0 = pm.math.flatten(eval_triangle, ndim=2)  # (T, D*F)\n",
    "        \n",
    "        W1 = pm.Normal(\"W1\", get_train_post(\"W1\"), net_sd, shape=(D*F, n_hidden))\n",
    "        b1_net = pm.Normal(\"b1_net\", get_train_post(\"b1_net\"), net_sd, shape=(n_hidden,))\n",
    "        h1 = silu(pm.math.dot(h0, W1) + b1_net)\n",
    "\n",
    "        W2 = pm.Normal(\"W2\", get_train_post(\"W2\"), net_sd, shape=(n_hidden, D))\n",
    "        b2_net = pm.Normal(\"b2_net\", get_train_post(\"b2_net\"), net_sd, shape=(D,))\n",
    "        p_raw = pm.math.dot(h1, W2) + b2_net\n",
    "\n",
    "\n",
    "        p_raw = pm.math.clip(p_raw, -10, 10)\n",
    "        p = pm.Deterministic(\"p\", pm.math.softmax(p_raw, axis=1))\n",
    "\n",
    "        mu = pm.Deterministic(\"mu\", lam[:, None] * p)\n",
    "        mu_clipped = pm.math.clip(mu, 1e-3, 1e4)\n",
    "\n",
    "        alpha = pm.Exponential(\"alpha\", 2)\n",
    "        z = pm.NegativeBinomial(\"z\", mu_clipped[mask], alpha, observed=eval_obs[mask])\n",
    "\n",
    "        idata = pm.sample(progressbar=progressbar, **sampler_kwargs())\n",
    "        return idata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50463f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PNN_nowcast(eval_range):\n",
    "    PNN_train_triangle = reporting_triangle[eval_range, :, :]\n",
    "    nowcast_pnn = NowcastPNN(past_units=M+model_D, max_delay=model_D, conv_channels=[16, 1], hidden_units=[16, 8], dropout_probs=[0.3, 0.1])\n",
    "    nowcast_pnn.load_state_dict(torch.load(f\"../src/outputs/weights/weights-{M+model_D}-{model_D}\"))\n",
    "\n",
    "    # Put model in eval mode with dropout active\n",
    "    nowcast_pnn.eval()\n",
    "    nowcast_pnn.drop1.train()\n",
    "    nowcast_pnn.drop2.train()\n",
    "\n",
    "    n_samples = 1000\n",
    "    preds = np.zeros(shape=(len(PNN_train_triangle), n_samples))\n",
    "    for i in range(n_samples):\n",
    "        matrix = torch.tensor(PNN_train_triangle)\n",
    "        preds[:, i] = nowcast_pnn(matrix).sample().numpy()\n",
    "        \n",
    "\n",
    "    PNN_preds = np.quantile(preds, 0.5, axis=1)\n",
    "    PNN_lower = np.percentile(preds, 2.5, axis=1)\n",
    "    PNN_upper = np.percentile(preds, 97.5, axis=1)\n",
    "    return PNN_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PNN.NowcastPNN import NowcastPNN\n",
    "import torch\n",
    "\n",
    "M = 0\n",
    "start_idx = 40\n",
    "len_eval = 40\n",
    "idata = get_BNN_nowcast(start_idx, len_eval, progressbar=True)\n",
    "\n",
    "\n",
    "PNN_train_triangle = reporting_triangle[start_idx - len_eval:start_idx, :, :]\n",
    "nowcast_pnn = NowcastPNN(past_units=M+model_D, max_delay=model_D, conv_channels=[16, 1], hidden_units=[16, 8], dropout_probs=[0.3, 0.1])\n",
    "nowcast_pnn.load_state_dict(torch.load(f\"../src/outputs/weights/weights-{M+model_D}-{model_D}\"))\n",
    "\n",
    "# Put model in eval mode with dropout active\n",
    "nowcast_pnn.eval()\n",
    "nowcast_pnn.drop1.train()\n",
    "nowcast_pnn.drop2.train()\n",
    "\n",
    "n_samples = 1000\n",
    "preds = np.zeros(shape=(len(train_triangle), n_samples))\n",
    "for i in range(n_samples):\n",
    "    matrix = torch.tensor(PNN_train_triangle)\n",
    "    preds[:, i] = nowcast_pnn(matrix).sample().numpy()\n",
    "    \n",
    "\n",
    "PNN_preds = np.quantile(preds, 0.5, axis=1)\n",
    "PNN_lower = np.percentile(preds, 2.5, axis=1)\n",
    "PNN_upper = np.percentile(preds, 97.5, axis=1)\n",
    "\n",
    "lam_post_samples = az.extract(idata, group='posterior', num_samples=1000)['lam']\n",
    "lam_med = np.percentile(lam_post_samples, 50, axis=1)\n",
    "lam_lower = np.percentile(lam_post_samples, 2.5, axis=1)\n",
    "lam_upper = np.percentile(lam_post_samples, 97.5, axis=1)\n",
    "\n",
    "\n",
    "y_plot = y_true[model_D + start_idx - len_eval:model_D + start_idx]\n",
    "y_plot.index = pd.to_datetime(y_plot.index)\n",
    "\n",
    "\n",
    "plt.plot(y_plot.index, y_plot, label='y')\n",
    "\n",
    "plt.plot(y_plot.index, lam_med, label='BNN', color='green')\n",
    "# plt.fill_between(y_plot.index, lam_lower, lam_upper, color='green', alpha=0.2, label='BNN 95% CI')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(y_plot.index, PNN_preds, label='PNN', color='orange')\n",
    "# plt.fill_between(y_plot.index, PNN_lower, PNN_upper, color='orange', alpha=0.2, label='PNN 95% CI')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(\"Number of Dengue Fever Cases in Sao Paulo, Brazil\")\n",
    "plt.xlabel(\"Date of First Symptom\")\n",
    "plt.ylabel(\"Case Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same day nowcast\n",
    "\n",
    "BNN_preds = []\n",
    "\n",
    "\n",
    "eval_range = list(range(40, 100))\n",
    "for t in eval_range:\n",
    "    print(t)\n",
    "    idata = get_BNN_nowcast(t, len_eval=40, progressbar=False)\n",
    "    lam_post_samples = az.extract(idata, group='posterior', num_samples=1000)['lam']\n",
    "    lam_pred = np.percentile(lam_post_samples, 50, axis=1)[-1]\n",
    "    BNN_preds.append(lam_pred)\n",
    "\n",
    "PNN_preds = get_PNN_nowcast(eval_range)\n",
    "\n",
    "\n",
    "y_plot = y_true[np.array(eval_range) + model_D]\n",
    "y_plot.index = pd.to_datetime(y_plot.index)\n",
    "\n",
    "\n",
    "plt.plot(y_plot.index, y_plot, label='y')\n",
    "\n",
    "plt.plot(y_plot.index, BNN_preds, label='BNN', color='green')\n",
    "# plt.fill_between(y_plot.index, lam_lower, lam_upper, color='green', alpha=0.2, label='BNN 95% CI')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(y_plot.index, PNN_preds, label='PNN', color='orange')\n",
    "# plt.fill_between(y_plot.index, PNN_lower, PNN_upper, color='orange', alpha=0.2, label='PNN 95% CI')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(\"Number of Dengue Fever Cases in Sao Paulo, Brazil\")\n",
    "plt.xlabel(\"Date of First Symptom\")\n",
    "plt.ylabel(\"Case Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NowcastingVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

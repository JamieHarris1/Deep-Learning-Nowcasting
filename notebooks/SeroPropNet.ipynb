{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6e0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from data_tools.data_utils import create_data_split\n",
    "from PNN.train_utils import train, EarlyStopper, train_type_name\n",
    "from PNN.NowcastPNN import PropNet, NowcastPNNDOW, TypePNN\n",
    "\n",
    "# Set seeds for batch shuffle and during training\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 123\n",
    "set_seed(seed)\n",
    "project_dir = project_dir = Path.cwd().parent\n",
    "D = 40\n",
    "M = 50\n",
    "train_prop = 0.7\n",
    "val_prop = 0.15\n",
    "test_prop = 0.15\n",
    "start_year = 2013\n",
    "\n",
    "deng_delays = pd.read_csv(project_dir / \"data\" / \"transformed\" / \"DENG_delays.csv\")\n",
    "denv_df = pd.read_csv(project_dir / \"data\" / \"transformed\" / \"denv_df.csv\")\n",
    "type_name_props = pd.read_csv(project_dir / \"data\" / \"transformed\" / \"type_name_props.csv\")\n",
    "\n",
    "deng_delays[\"Collection date\"] = pd.to_datetime(deng_delays[\"Collection date\"])\n",
    "deng_delays = deng_delays.set_index(\"Collection date\")\n",
    "\n",
    "type_name_all = type_name_props.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88957a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop last D days as they are incomplete\n",
    "complete_df = deng_delays.iloc[D-1: -D+1]\n",
    "complete_df = complete_df[complete_df.index.to_period(\"Y\") >= pd.Period(start_year, freq=\"Y\")]\n",
    "# First D days are not usable\n",
    "n_usable_obs = len(complete_df)\n",
    "\n",
    "# Split the number of usable obs over the 3 datasets\n",
    "train_end_idx = int(train_prop*n_usable_obs)\n",
    "val_end_idx = train_end_idx + int(val_prop*n_usable_obs)\n",
    "\n",
    "train_df = complete_df.iloc[0: train_end_idx]\n",
    "val_df = complete_df.iloc[train_end_idx - D : val_end_idx]\n",
    "test_df = complete_df.iloc[val_end_idx - D : ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f88def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2013-02-09', '2013-02-10', '2013-02-11', '2013-02-12',\n",
      "               '2013-02-13', '2013-02-14', '2013-02-15', '2013-02-16',\n",
      "               '2013-02-17', '2013-02-18',\n",
      "               ...\n",
      "               '2020-08-18', '2020-08-19', '2020-08-20', '2020-08-21',\n",
      "               '2020-08-22', '2020-08-23', '2020-08-24', '2020-08-25',\n",
      "               '2020-08-26', '2020-08-27'],\n",
      "              dtype='datetime64[ns]', name='Collection date', length=2757, freq=None)\n",
      "DatetimeIndex(['2020-07-19', '2020-07-20', '2020-07-21', '2020-07-22',\n",
      "               '2020-07-23', '2020-07-24', '2020-07-25', '2020-07-26',\n",
      "               '2020-07-27', '2020-07-28',\n",
      "               ...\n",
      "               '2022-03-31', '2022-04-01', '2022-04-02', '2022-04-03',\n",
      "               '2022-04-04', '2022-04-05', '2022-04-06', '2022-04-07',\n",
      "               '2022-04-08', '2022-04-09'],\n",
      "              dtype='datetime64[ns]', name='Collection date', length=630, freq=None)\n",
      "DatetimeIndex(['2022-03-01', '2022-03-02', '2022-03-03', '2022-03-04',\n",
      "               '2022-03-05', '2022-03-06', '2022-03-07', '2022-03-08',\n",
      "               '2022-03-09', '2022-03-10',\n",
      "               ...\n",
      "               '2023-11-13', '2023-11-14', '2023-11-15', '2023-11-16',\n",
      "               '2023-11-17', '2023-11-18', '2023-11-19', '2023-11-20',\n",
      "               '2023-11-21', '2023-11-22'],\n",
      "              dtype='datetime64[ns]', name='Collection date', length=632, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.index)\n",
    "print(val_df.index)\n",
    "print(test_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3644c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_name_tensor = np.load(project_dir / \"data\" / \"transformed\" / \"type_name_tensor.npy\")\n",
    "start_date = str(denv_df['Collection date'].min())\n",
    "end_date = str(pd.to_datetime(denv_df['Collection date']).max() + pd.DateOffset(months=1))\n",
    "\n",
    "\n",
    "denv_dates = pd.date_range(start_date,end_date, freq='ME').to_period('M')\n",
    "\n",
    "D_g = type_name_tensor.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca46578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.33333334, 0.        , 0.6666667 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class type_nameDataset:\n",
    "    def __init__(self, dates, type_name_tensor, type_name_props, D_g):\n",
    "        self.dates = dates\n",
    "        self.type_name_tensor = type_name_tensor\n",
    "        self.type_name_props = type_name_props\n",
    "        self.D_g = D_g\n",
    "\n",
    "    def get_type_name_triangle(self, date):\n",
    "        date = pd.to_datetime(date).to_period('M')\n",
    "        idx_range = self.dates < date\n",
    "        type_name_obs = self.type_name_tensor[:, idx_range, :]\n",
    "        type_name_obs = type_name_obs[:, -self.D_g:, :]\n",
    "        mask = self.get_mask()\n",
    "        type_name_obs[:, ~mask] = 0\n",
    "        type_name_obs = type_name_obs / type_name_obs.max()\n",
    "        return type_name_obs\n",
    "\n",
    "    def get_type_name_prop(self, date):\n",
    "        date = pd.to_datetime(date).to_period('M')\n",
    "        idx_vals = pd.to_datetime(self.type_name_props['Collection date'].values).to_period(\"M\") == date\n",
    "\n",
    "        row = self.type_name_props.iloc[idx_vals, 1:]\n",
    "        return row.to_numpy().flatten()\n",
    "\n",
    "    def get_mask(self):\n",
    "        mask_matrix = np.ones(shape=(self.D_g, self.D_g), dtype=bool)\n",
    "        for i in range(self.D_g):\n",
    "            for j in range(self.D_g):\n",
    "                if i + j > self.D_g - 1:\n",
    "                    mask_matrix[i, j] = False\n",
    "        return mask_matrix\n",
    "    \n",
    "type_name_obj = type_nameDataset(denv_dates, type_name_tensor, type_name_props, D_g)\n",
    "type_name_obj.get_type_name_triangle(\"2018-01-01\").shape\n",
    "type_name_obj.get_type_name_prop(\"2018-02-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportingDataset(Dataset):\n",
    "    # first available datapoint is index self.D - 1,\n",
    "    # e.g D=40, then self.df[39] is first day with a reporting triangle of length 40 \n",
    "\n",
    "    def __init__(self, df, D, M, max_val, type_name_obj, label_type, device):\n",
    "        self.M = M\n",
    "        self.D = D\n",
    "        self.dates = pd.to_datetime(df.copy().index[self.M-1:])\n",
    "        self.df = np.array(df.copy(), dtype = np.float32)\n",
    "        self.type_name_obj = type_name_obj\n",
    "        self.max_val = max_val\n",
    "        self.label_type = label_type\n",
    "        self.device = device\n",
    "\n",
    "        assert self.label_type in (\"y\", \"z\"), 'label_type must either be \"y\" or \"z\"'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.M + 1\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = idx + self.M\n",
    "        obs = self.df[t-self.M: t]\n",
    "\n",
    "        # Create observed reporting triangle\n",
    "        mask = self.get_mask()\n",
    "        obs_masked = obs.copy() / self.max_val\n",
    "        if self.M <= self.D:\n",
    "            mask = mask[-self.M:,:]\n",
    "            obs_masked[-self.M:, :][~mask] = 0\n",
    "        else:\n",
    "            obs_masked[-self.D:, :][~mask] = 0\n",
    "\n",
    "        obs_masked = torch.tensor(obs_masked, dtype=torch.float32)\n",
    "        obs_masked = obs_masked.to(self.device)\n",
    "\n",
    "        # Get day of the week and week num\n",
    "        date = self.get_date(idx)\n",
    "        dow = torch.tensor(date.weekday(), dtype=torch.int32)\n",
    "        dow.to(self.device)\n",
    "        # week = torch.tensor(date.isocalendar().week - 1, dtype=torch.int32)\n",
    "        # week.to(self.device)\n",
    "\n",
    "        type_name_obs = self.type_name_obj.get_type_name_triangle(date)\n",
    "        type_name_prop = self.type_name_obj.get_type_name_prop(date)\n",
    "\n",
    "        # Create y label\n",
    "        y_label = torch.tensor(obs[self.M - 1, :].sum(), dtype=torch.float32)\n",
    "        y_label = (y_label * type_name_prop)\n",
    "        y_label = np.round(y_label)\n",
    "        y_label.to(self.device)\n",
    "        return (obs_masked, dow, type_name_obs), (y_label, type_name_prop)\n",
    "        \n",
    "    \n",
    "    def get_mask(self):\n",
    "        mask_matrix = np.ones(shape=(self.D, self.D), dtype=bool)\n",
    "        for i in range(self.D):\n",
    "            for j in range(self.D):\n",
    "                if i + j > self.D - 1:\n",
    "                    mask_matrix[i, j] = False\n",
    "        return mask_matrix\n",
    "\n",
    "    def get_date(self, idx):\n",
    "        return self.dates[idx].date()\n",
    "    \n",
    "    def get_y(self, idx):\n",
    "        t = idx + self.M\n",
    "        y = np.array(self.df[t-1].sum())\n",
    "    \n",
    "        date = self.get_date(idx)\n",
    "        type_name_prop = self.type_name_obj.get_type_name_prop(date)\n",
    "        y = (y * type_name_prop)\n",
    "        return y\n",
    "\n",
    "\n",
    "max_val = train_df.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea160b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(dataset, model, label_type):\n",
    "    eval_loader = DataLoader(dataset, batch_size=dataset.__len__(), shuffle=False)\n",
    "\n",
    "    # Put model in eval mode with dropout active\n",
    "    model.eval()\n",
    "    model.drop_count1.train()\n",
    "    model.drop_count2.train()\n",
    "    model.drop_prop1.train()\n",
    "    model.drop_prop2.train()\n",
    "\n",
    "    (obs_masked, dow, type_name_obs), (y_label, p_true) = next(iter(eval_loader))\n",
    "    obs_masked = obs_masked.to(\"cpu\")\n",
    "    dow = dow.to(\"cpu\")\n",
    "    type_name_obs = type_name_obs.to(\"cpu\")\n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    n_type_name = type_name_obs.shape[1]\n",
    "\n",
    "    n_samples = 50\n",
    "    preds = np.zeros(shape=(dataset.__len__(), n_samples, n_type_name))\n",
    "    for i in range(n_samples):\n",
    "        dist, p_pred, active_type_names = model(obs_masked, dow, type_name_obs)\n",
    "        samples = dist.sample().numpy()\n",
    "        preds[:, i, :][active_type_names] = samples\n",
    "\n",
    "    return preds\n",
    "\n",
    "def plot_preds(preds, dataset, type_name_all, title, other_preds=False, other_preds_label=False):\n",
    "    preds_median = np.quantile(preds, 0.5, axis=1)\n",
    "    dates = pd.to_datetime(dataset.dates)\n",
    "    colors = plt.cm.get_cmap('tab10', len(type_name_all))\n",
    "    colors = [colors(i) for i in range(len(type_name_all))]\n",
    "\n",
    "    for s, type_name in enumerate(type_name_all):\n",
    "        plt.plot(dates, preds_median[:, s], label=f'Preds: {type_name}', color=colors[s], linestyle='-')\n",
    "        y_true = [dataset.get_y(i)[s] for i in range(len(dataset))]\n",
    "        plt.plot(dates, y_true, label=f'True y: {type_name}', color=\"black\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.title(f\"{title} ({type_name})\", fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8af14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "complete_dataset = ReportingDataset(complete_df, D, M, max_val, type_name_obj, label_type='y', device=device)\n",
    "train_dataset = ReportingDataset(train_df, D, M, max_val, type_name_obj, label_type='y', device=device)\n",
    "val_dataset = ReportingDataset(val_df, D, M, max_val,type_name_obj, label_type='y', device=device)\n",
    "test_dataset = ReportingDataset(test_df, D, M, max_val,type_name_obj, label_type='y', device=device)\n",
    "\n",
    "# Create dataloaders, shuffle trainign data for better training\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "early_stopper = EarlyStopper(patience=30, past_units=M, max_delay=D, weeks=False, future_obs=0, random_split=False, dow = True)\n",
    "type_name_net = TypePNN(max_val=max_val, D=D, M=M, D_g=D_g, n_type_name=len(type_name_all))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993f0380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[1.4432e-01, 1.6465e-01, 1.6687e-01,  ..., 6.8318e-04, 1.7079e-04,\n",
       "           6.8318e-04],\n",
       "          [1.2912e-01, 2.2152e-01, 1.4586e-01,  ..., 1.0248e-03, 8.5397e-04,\n",
       "           5.1238e-04],\n",
       "          [1.6772e-01, 1.8958e-01, 1.9829e-01,  ..., 1.1956e-03, 5.1238e-04,\n",
       "           1.0248e-03],\n",
       "          ...,\n",
       "          [3.8292e-01, 3.3561e-01, 2.1964e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00],\n",
       "          [2.7737e-01, 2.9137e-01, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00],\n",
       "          [2.6371e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00]]),\n",
       "  tensor(5, dtype=torch.int32),\n",
       "  tensor(12, dtype=torch.int32),\n",
       "  array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       "  \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       "  \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       "  \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]])),\n",
       " (tensor([  199.,     0.,   133., 16711.], dtype=torch.float64),\n",
       "  array([0.01167315, 0.        , 0.0077821 , 0.98054475])))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7871a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  199.,     0.,   133., 16711.], dtype=torch.float64),\n",
       " array([0.01167315, 0.        , 0.0077821 , 0.98054475]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(obs_masked, dow, type_name_obs), y_label = next(iter(train_dataset))\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3669523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train loss: 1.65e+05 - Val loss: 1.62e+06 - ES count: 0\n",
      "Epoch 2 - Train loss: 1.06e+05 - Val loss: 1.51e+06 - ES count: 0\n",
      "Epoch 3 - Train loss: 8.47e+04 - Val loss: 2.34e+06 - ES count: 1\n",
      "Epoch 4 - Train loss: 7.58e+04 - Val loss: 1.37e+06 - ES count: 0\n",
      "Epoch 5 - Train loss: 7.14e+04 - Val loss: 1.26e+06 - ES count: 0\n",
      "Epoch 6 - Train loss: 5.98e+04 - Val loss: 1.21e+06 - ES count: 0\n",
      "Epoch 7 - Train loss: 5.46e+04 - Val loss: 1.34e+06 - ES count: 1\n",
      "Epoch 8 - Train loss: 5.08e+04 - Val loss: 1.28e+06 - ES count: 2\n",
      "Epoch 9 - Train loss: 5.09e+04 - Val loss: 1.64e+06 - ES count: 3\n",
      "Epoch 10 - Train loss: 6.01e+04 - Val loss: 1.29e+06 - ES count: 4\n",
      "Epoch 11 - Train loss: 5.64e+04 - Val loss: 1.2e+06 - ES count: 0\n",
      "Epoch 12 - Train loss: 5.34e+04 - Val loss: 1.19e+06 - ES count: 0\n",
      "Epoch 13 - Train loss: 5.16e+04 - Val loss: 1.06e+06 - ES count: 0\n",
      "Epoch 14 - Train loss: 5.01e+04 - Val loss: 1.14e+06 - ES count: 1\n",
      "Epoch 15 - Train loss: 4.81e+04 - Val loss: 1.1e+06 - ES count: 2\n",
      "Epoch 16 - Train loss: 4.73e+04 - Val loss: 1.05e+06 - ES count: 0\n",
      "Epoch 17 - Train loss: 4.76e+04 - Val loss: 1.22e+06 - ES count: 1\n",
      "Epoch 18 - Train loss: 4.71e+04 - Val loss: 1.12e+06 - ES count: 2\n",
      "Epoch 19 - Train loss: 4.58e+04 - Val loss: 1.12e+06 - ES count: 3\n",
      "Epoch 20 - Train loss: 4.53e+04 - Val loss: 1.19e+06 - ES count: 4\n",
      "Epoch 21 - Train loss: 4.51e+04 - Val loss: 1.09e+06 - ES count: 5\n",
      "Epoch 22 - Train loss: 4.4e+04 - Val loss: 1.13e+06 - ES count: 6\n",
      "Epoch 23 - Train loss: 4.48e+04 - Val loss: 8.14e+05 - ES count: 0\n",
      "Epoch 24 - Train loss: 4.53e+04 - Val loss: 1.39e+06 - ES count: 1\n",
      "Epoch 25 - Train loss: 4.34e+04 - Val loss: 1.81e+06 - ES count: 2\n",
      "Epoch 26 - Train loss: 4.53e+04 - Val loss: 1.24e+06 - ES count: 3\n",
      "Epoch 27 - Train loss: 4.4e+04 - Val loss: 1.14e+06 - ES count: 4\n",
      "Epoch 28 - Train loss: 4.26e+04 - Val loss: 1.18e+06 - ES count: 5\n",
      "Epoch 29 - Train loss: 4.17e+04 - Val loss: 1.22e+06 - ES count: 6\n",
      "Epoch 30 - Train loss: 4.17e+04 - Val loss: 1.47e+06 - ES count: 7\n",
      "Epoch 31 - Train loss: 5.33e+04 - Val loss: 1.22e+06 - ES count: 8\n",
      "Epoch 32 - Train loss: 5.33e+04 - Val loss: 1.2e+06 - ES count: 9\n",
      "Epoch 33 - Train loss: 5.01e+04 - Val loss: 1.21e+06 - ES count: 10\n",
      "Epoch 34 - Train loss: 4.95e+04 - Val loss: 1.23e+06 - ES count: 11\n",
      "Epoch 35 - Train loss: 4.71e+04 - Val loss: 1.22e+06 - ES count: 12\n",
      "Epoch 36 - Train loss: 4.67e+04 - Val loss: 1.22e+06 - ES count: 13\n",
      "Epoch 37 - Train loss: 4.5e+04 - Val loss: 1.26e+06 - ES count: 14\n",
      "Epoch 38 - Train loss: 4.58e+04 - Val loss: 1.23e+06 - ES count: 15\n",
      "Epoch 39 - Train loss: 5.5e+04 - Val loss: 1.31e+06 - ES count: 16\n",
      "Epoch 40 - Train loss: 5.22e+04 - Val loss: 1.35e+06 - ES count: 17\n",
      "Epoch 41 - Train loss: 4.88e+04 - Val loss: 1.29e+06 - ES count: 18\n",
      "Epoch 42 - Train loss: 4.72e+04 - Val loss: 1.26e+06 - ES count: 19\n",
      "Epoch 43 - Train loss: 4.49e+04 - Val loss: 1.36e+06 - ES count: 20\n",
      "Epoch 44 - Train loss: 4.45e+04 - Val loss: 1.49e+06 - ES count: 21\n",
      "Epoch 45 - Train loss: 4.29e+04 - Val loss: 1.33e+06 - ES count: 22\n",
      "Epoch 46 - Train loss: 4.18e+04 - Val loss: 1.28e+06 - ES count: 23\n",
      "Epoch 47 - Train loss: 4.14e+04 - Val loss: 1.26e+06 - ES count: 24\n",
      "Epoch 48 - Train loss: 4.07e+04 - Val loss: 1.29e+06 - ES count: 25\n",
      "Epoch 49 - Train loss: 4.09e+04 - Val loss: 1.4e+06 - ES count: 26\n",
      "Epoch 50 - Train loss: 4.12e+04 - Val loss: 1.38e+06 - ES count: 27\n",
      "Epoch 51 - Train loss: 3.94e+04 - Val loss: 1.27e+06 - ES count: 28\n",
      "Epoch 52 - Train loss: 4.05e+04 - Val loss: 1.32e+06 - ES count: 29\n"
     ]
    }
   ],
   "source": [
    "train_type_name(type_name_net, num_epochs=200, train_loader=train_loader, val_loader=val_loader, early_stopper=early_stopper, loss_fct=\"nll\", device = device, dow = True, label_type='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "322a01cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m type_name_pnn = TypePNN(max_val=max_val, D=D, M=M, D_g=D_g, n_type_name=\u001b[38;5;28mlen\u001b[39m(type_name_all))\n\u001b[32m      4\u001b[39m type_name_pnn.load_state_dict(torch.load(project_dir /\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mweights-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_preds_prop = \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_name_pnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m plot_preds(train_preds_prop, train_dataset, type_name_all=type_name_all, title=\u001b[33m\"\u001b[39m\u001b[33mSame Day Nowcast Train Performance (type_namePNN)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m val_preds = eval_model(val_dataset, type_name_pnn, label_type=\u001b[33m'\u001b[39m\u001b[33mz\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36meval_model\u001b[39m\u001b[34m(dataset, model, label_type)\u001b[39m\n\u001b[32m      8\u001b[39m model.drop_prop1.train()\n\u001b[32m      9\u001b[39m model.drop_prop2.train()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m (obs_masked, dow, type_name_obs), (y_label, p_true) = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(eval_loader))\n\u001b[32m     12\u001b[39m obs_masked = obs_masked.to(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m dow = dow.to(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "## Load best set of weights on test/validation set onto CPU for evaluation\n",
    "type_name_pnn = TypePNN(max_val=max_val, D=D, M=M, D_g=D_g, n_type_name=len(type_name_all))\n",
    "\n",
    "type_name_pnn.load_state_dict(torch.load(project_dir /\"src\" / \"outputs\" / \"weights\" / f\"weights-{M}-{D}\"))\n",
    "\n",
    "train_preds_prop = eval_model(train_dataset, type_name_pnn, label_type='z')\n",
    "plot_preds(train_preds_prop, train_dataset, type_name_all=type_name_all, title=\"Same Day Nowcast Train Performance (type_namePNN)\")\n",
    "\n",
    "val_preds = eval_model(val_dataset, type_name_pnn, label_type='z')\n",
    "plot_preds(val_preds, val_dataset, type_name_all=type_name_all, title=\"Same Day Nowcast Validation Performance (type_namePNN)\")\n",
    "\n",
    "test_preds = eval_model(test_dataset, type_name_pnn, label_type='z')\n",
    "plot_preds(test_preds, test_dataset, type_name_all=type_name_all, title=\"Same Day Nowcast Test Performance (type_namePNN)\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NowcastingVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a26a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from properscoring import crps_ensemble\n",
    "import random\n",
    "import pymc as pm\n",
    "from patsy import dmatrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "project_dir = Path.cwd().parent\n",
    "\n",
    "from data_tools.data_utils import SimulateSero, PartialCountDataset, TrueCountDataset\n",
    "from model_tools.train_utils import BaseTrain, SeroTrain, DirectTrain\n",
    "from model_tools.models import SimSero, DirectSero\n",
    "from model_tools.evaluation import eval_sero_pnn, plot_sero_pnn_preds, eval_pnn, eval_direct_sero\n",
    "\n",
    "start_year = 2022\n",
    "end_year = 2022\n",
    "data_split = [0.7, 0.15, 0.15]\n",
    "seed = 123\n",
    "\n",
    "D = 40\n",
    "M = 50\n",
    "T = 40\n",
    "Q = 40\n",
    "N = 4\n",
    "S = 500\n",
    "chains = 1\n",
    "cores = 1\n",
    "\n",
    "\n",
    "# 123, 2019, 2023, 15\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68492925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sero:  DENV-1\n",
      "Saving sero:  DENV-2\n",
      "Saving sero:  DENV-3\n",
      "Saving sero:  DENV-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/9g0vtmkj22j_xbhxyrknnv140000gn/T/ipykernel_31227/573279697.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  denv_df['Collection date'] = pd.to_datetime(denv_df['Collection date'])\n"
     ]
    }
   ],
   "source": [
    "# Simulate Data\n",
    "# True counts * Constant sero prop vec * constant delay vec from average across world samples\n",
    "p_sero = np.array([0.9, 0.0, 0.05, 0.05])\n",
    "sero_all = [\"DENV-1\", \"DENV-2\", \"DENV-3\", \"DENV-4\"]\n",
    "\n",
    "\n",
    "\n",
    "delays_df = pd.read_csv(project_dir / \"data\" / \"transformed\" / \"DENG_delays.csv\")\n",
    "delays_df = delays_df.set_index(\"Collection date\")\n",
    "delays_df.index = pd.to_datetime(delays_df.index)\n",
    "\n",
    "y_true = delays_df.sum(1)[:-2]\n",
    "y_true_df = y_true.groupby(y_true.index.to_period(\"M\")).sum()\n",
    "y_true = np.array(y_true_df)\n",
    "const = 10*np.ones_like(y_true)\n",
    "\n",
    "denv_df = pd.read_csv(project_dir / \"data\" / \"transformed\" / \"denv_df.csv\")\n",
    "\n",
    "denv_df = denv_df[denv_df['Delay'] < 60]\n",
    "\n",
    "# If your original denv_df dates are datetime\n",
    "denv_df['Collection date'] = pd.to_datetime(denv_df['Collection date'])\n",
    "\n",
    "start_month = pd.to_datetime(delays_df.index.min())\n",
    "end_month = pd.to_datetime(delays_df.index.max())\n",
    "\n",
    "# Create a DataFrame of month start dates as datetime (not Period)\n",
    "dates = pd.DataFrame({\n",
    "    \"Collection date\": pd.date_range(start=start_month, end=end_month, freq='MS')\n",
    "})\n",
    "\n",
    "df = denv_df[denv_df['Sero'] == \"DENV-1\"] \\\n",
    "    .groupby(['Sero', 'Collection date', 'Delay']) \\\n",
    "    .size() \\\n",
    "    .reset_index(name='count')\n",
    "\n",
    "df = df.pivot(index='Collection date', columns='Delay', values='count')\n",
    "\n",
    "# Ensure df.index is datetime as well\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "p_delay = np.array(df.fillna(0).mean(0) / df.fillna(0).mean(0).sum())\n",
    "\n",
    "p_sero = p_sero[:, np.newaxis, np.newaxis]   # shape (S,1,1)\n",
    "const = const[np.newaxis, :, np.newaxis]  # shape (1,T,1)\n",
    "p_delay = p_delay[np.newaxis, np.newaxis, :Q]  # shape (1,1,D)\n",
    "\n",
    "# multiply to get (S,T,D)\n",
    "sero_tensor = p_sero * const * p_delay\n",
    "sero_tensor = sero_tensor.round()\n",
    "for s,sero in enumerate(sero_all):\n",
    "    sero_df = pd.DataFrame(sero_tensor[s, :, :])\n",
    "    sero_df.index = y_true_df.index\n",
    "    sero_df.to_csv(project_dir / \"data\" / \"model\" / \"sero_dfs\" / f\"{sero}.csv\", index=True)\n",
    "    print(\"Saving sero: \", sero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f33745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 40)\n"
     ]
    }
   ],
   "source": [
    "print(p_delay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd7ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Serotype obj\n",
    "sero_tensor = []\n",
    "base_folder = project_dir / \"data\" / \"model\" / \"sero_dfs\"\n",
    "files = [f for f in os.listdir(base_folder) if f.endswith('.csv')]\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dates = df['Collection date']\n",
    "    sero_df = df.drop(columns=\"Collection date\")\n",
    "    sero_tensor.append(sero_df)\n",
    "sero_tensor = np.array(sero_tensor)\n",
    "\n",
    "sero_dataset = SimulateSero(sero_tensor, dates, T=T, Q=Q, N=N, prop_vec=p_sero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a78285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count obj\n",
    "delays_df = pd.read_csv(project_dir / \"data\" / \"transformed\" / \"DENG_delays.csv\")\n",
    "delays_df['Collection date'] = pd.to_datetime(delays_df['Collection date'])\n",
    "\n",
    "partial_count_dataset = PartialCountDataset(delays_df, D=D, M=M)\n",
    "true_count_dataset = TrueCountDataset(delays_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c82ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of 2023 appears to have some incomplete data\n",
    "if end_year == 2023:\n",
    "    dates = list(pd.date_range(f\"{start_year}-01-01\",f\"{end_year}-12-25\", freq='D'))\n",
    "else:\n",
    "    dates = list(pd.date_range(f\"{start_year}-01-01\",f\"{end_year}-12-31\", freq='D'))\n",
    "data_split_sizes = (np.array(data_split) * len(dates)).astype(int)\n",
    "\n",
    "# Ensure dates line up fully, also removing 2023-12-31 as doesn't appear complete\n",
    "data_split_sizes[-1] = len(dates) - data_split_sizes[:-1].sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97031895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def silu(x):\n",
    "    return x * pm.math.sigmoid(x)\n",
    "\n",
    "\n",
    "def sampler_kwargs():\n",
    "    return dict(\n",
    "        nuts_sampler=\"nutpie\",\n",
    "        cores=cores,\n",
    "        init=\"adapt_diag\",\n",
    "        chains=chains,\n",
    "        draws=S,\n",
    "        tune=500,\n",
    "        target_accept=0.95,\n",
    "        max_treedepth=10,\n",
    "        nuts_sampler_kwargs={\"backend\": \"jax\", \"gradient_backend\": \"jax\"}\n",
    "    )\n",
    "\n",
    "def get_mask(D):\n",
    "        mask_matrix = np.ones(shape=(D, D), dtype=bool)\n",
    "        for i in range(D):\n",
    "            for j in range(D):\n",
    "                if i + j > D - 1:\n",
    "                    mask_matrix[i, j] = False\n",
    "        return mask_matrix\n",
    "\n",
    "def create_fourier_features(t, n, p=10.0):\n",
    "    x = 2 * np.pi * (np.arange(n) + 1) * t[:, None] / p\n",
    "    return np.concatenate((np.cos(x), np.sin(x)), axis=1)\n",
    "\n",
    "class SeroBNNDataset(Dataset):\n",
    "    def __init__(self, partial_count_obj, true_count_obj, sero_obj, dates, S, T, Q):\n",
    "        self.partial_count_obj = partial_count_obj\n",
    "        self.true_count_obj = true_count_obj\n",
    "        self.sero_obj = sero_obj\n",
    "        self.dates = dates\n",
    "        self.S = S\n",
    "        self.T = T\n",
    "        self.Q = Q\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dates)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        date = self.dates[index]\n",
    "        window_dates = [date - pd.Timedelta(days=i) for i in range(M)]\n",
    "        window_dates = sorted(window_dates)\n",
    "        Z_obs = self.partial_count_obj.get_obs(date)\n",
    "\n",
    "        prop_mat = [self.sero_obj.get_prop_vec(date) for day in window_dates]\n",
    "\n",
    "\n",
    "        y_sero_true = self.true_count_obj.get_y_prop(date, )\n",
    "        y_sero_true = np.array(y_true)\n",
    "        dow = date.day_of_week\n",
    "\n",
    "        sero_obs = self.sero_obj.get_obs(date)\n",
    "        return Z_obs, sero_obs, y_sero_true, window_dates\n",
    "    \n",
    "set_seed(seed)\n",
    "sero_props = pd.read_csv(project_dir / \"data\" / \"transformed\" / \"sero_props.csv\")\n",
    "\n",
    "\n",
    "sero_pnn_dataset = SeroBNNDataset(partial_count_dataset, true_count_dataset, sero_dataset, dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb98ba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.18360376e-02, 1.52177626e-02, 1.53714774e-02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [8.36891546e-04, 2.20324509e-03, 2.08368915e-03, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.22032451e-03, 2.57045260e-03, 1.38343296e-03, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.38257899e-02, 3.53543980e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[6.57557643e-04, 8.45431255e-04, 8.53970965e-04, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [5.97779675e-04, 1.16140051e-03, 1.87019641e-03, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 8.53970965e-06],\n",
       "        [1.50640478e-02, 3.96584116e-02, 3.75064048e-02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.32365500e-03, 1.96413322e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.23740393e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[1.18360376e-02, 1.52177626e-02, 1.53714774e-02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [8.36891546e-04, 2.20324509e-03, 2.08368915e-03, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.22032451e-03, 2.57045260e-03, 1.38343296e-03, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.38257899e-02, 3.53543980e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[6.57557643e-04, 8.45431255e-04, 8.53970965e-04, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [5.97779675e-04, 1.16140051e-03, 1.87019641e-03, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 8.53970965e-06],\n",
       "        [1.50640478e-02, 3.96584116e-02, 3.75064048e-02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.32365500e-03, 1.96413322e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.23740393e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_obs, sero_obs, y_true, y_sero_true, window_dates = sero_pnn_dataset.__getitem__(0)\n",
    "Z_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "t = np.arange(0, M)\n",
    "t_week = t % 7\n",
    "t_norm = t / M\n",
    "\n",
    "n = 14\n",
    "fourier_basis_biweek = create_fourier_features(t, n=n, p=3.5)\n",
    "fourier_basis_week = create_fourier_features(t, n=n, p=7)\n",
    "\n",
    "fourier_basis_biweek = fourier_basis_biweek - fourier_basis_biweek.mean(0, keepdims=True)\n",
    "fourier_basis_week = fourier_basis_week - fourier_basis_week.mean(0, keepdims=True)\n",
    "\n",
    "spline_trend = dmatrix(\n",
    "    \"bs(t, df=14, degree=3, include_intercept=False)\", {\"t\": t_norm}, return_type='dataframe'\n",
    ")\n",
    "X_trend = np.asarray(spline_trend)\n",
    "\n",
    "spline_week = dmatrix(\n",
    "    \"cc(t_week, df=7)\", {\"t_week\": t_week}, return_type='dataframe'\n",
    ")\n",
    "X_week = np.asarray(spline_week)\n",
    "\n",
    "t_input = np.arange(M)[:, None] / M\n",
    "time_input = np.concatenate([t_input, fourier_basis_biweek, fourier_basis_week], axis=1)\n",
    "\n",
    "mask = np.ones((M,D), dtype=bool)\n",
    "mask[-D:,:] = get_mask(D)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NowcastingVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
